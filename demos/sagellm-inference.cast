{"version": 2, "width": 100, "height": 24, "timestamp": 1769778985, "env": {"SHELL": "/bin/bash", "TERM": "xterm-256color"}}
[0.0, "o", "\u001b[1;32muser@sagellm\u001b[0m:\u001b[1;34m~\u001b[0m$ "]
[0.5, "o", "s"]
[0.6, "o", "a"]
[0.7, "o", "g"]
[0.7999999999999999, "o", "e"]
[0.8999999999999999, "o", "-"]
[0.9999999999999999, "o", "l"]
[1.0999999999999999, "o", "l"]
[1.2, "o", "m"]
[1.3, "o", " "]
[1.4000000000000001, "o", "r"]
[1.5000000000000002, "o", "u"]
[1.6000000000000003, "o", "n"]
[1.7000000000000004, "o", " "]
[1.8000000000000005, "o", "-"]
[1.9000000000000006, "o", "p"]
[2.0000000000000004, "o", " "]
[2.1000000000000005, "o", "\""]
[2.2000000000000006, "o", "E"]
[2.3000000000000007, "o", "x"]
[2.400000000000001, "o", "p"]
[2.500000000000001, "o", "l"]
[2.600000000000001, "o", "a"]
[2.700000000000001, "o", "i"]
[2.800000000000001, "o", "n"]
[2.9000000000000012, "o", " "]
[3.0000000000000013, "o", "q"]
[3.1000000000000014, "o", "u"]
[3.2000000000000015, "o", "a"]
[3.3000000000000016, "o", "n"]
[3.4000000000000017, "o", "t"]
[3.5000000000000018, "o", "u"]
[3.600000000000002, "o", "m"]
[3.700000000000002, "o", " "]
[3.800000000000002, "o", "p"]
[3.900000000000002, "o", "h"]
[4.000000000000002, "o", "y"]
[4.100000000000001, "o", "s"]
[4.200000000000001, "o", "i"]
[4.300000000000001, "o", "c"]
[4.4, "o", "s"]
[4.5, "o", "\""]
[4.6, "o", " "]
[4.699999999999999, "o", "-"]
[4.799999999999999, "o", "-"]
[4.899999999999999, "o", "b"]
[4.999999999999998, "o", "a"]
[5.099999999999998, "o", "c"]
[5.1999999999999975, "o", "k"]
[5.299999999999997, "o", "e"]
[5.399999999999997, "o", "n"]
[5.4999999999999964, "o", "d"]
[5.599999999999996, "o", " "]
[5.699999999999996, "o", "a"]
[5.799999999999995, "o", "s"]
[5.899999999999995, "o", "c"]
[5.999999999999995, "o", "e"]
[6.099999999999994, "o", "n"]
[6.199999999999994, "o", "d"]
[6.299999999999994, "o", "\r\n"]
[6.499999999999994, "o", "\r\n\u001b[1m\ud83d\ude80 sageLLM Inference\u001b[0m\r\n\r\n"]
[6.549999999999994, "o", "  Model: \u001b[36mdeepseek-coder-33b\u001b[0m\r\n"]
[6.599999999999993, "o", "  Backend: ascend\r\n"]
[6.649999999999993, "o", "  Prompt: Explain quantum physics\r\n"]
[6.699999999999993, "o", "\r\n"]
[6.749999999999993, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - LLMEngine created: model=deepseek-coder-33b, backend=ascend, comm=auto\r\n"]
[6.799999999999993, "o", "Loading model...\r\n"]
[7.3499999999999925, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - Starting LLMEngine with model: deepseek-coder-33b\r\n"]
[7.399999999999992, "o", "2026-01-30 21:16:25,200 - sagellm_backend.providers.ascend - INFO - AscendBackendProvider initialized on npu:0\r\n"]
[7.449999999999992, "o", "2026-01-30 21:16:25,200 - sagellm_backend.registry - INFO - Created provider: ascend -> Huawei Ascend 910B\r\n"]
[7.499999999999992, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - Backend initialized: ascend (Huawei Ascend 910B)\r\n"]
[7.849999999999992, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - Loading tokenizer...\r\n"]
[8.09999999999999, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - Model loaded: deepseek-coder-33b\r\n"]
[8.149999999999991, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - LLMEngine started successfully\r\n"]
[8.199999999999992, "o", "\ud83d\udcdd Output:\r\n"]
[8.449999999999992, "o", "Quantum"]
[8.509999999999993, "o", " "]
[8.569999999999993, "o", "physics"]
[8.629999999999994, "o", " "]
[8.689999999999994, "o", "studies"]
[8.749999999999995, "o", " "]
[8.809999999999995, "o", "matter"]
[8.869999999999996, "o", " "]
[8.929999999999996, "o", "and"]
[8.989999999999997, "o", " "]
[9.049999999999997, "o", "energy"]
[9.109999999999998, "o", " "]
[9.169999999999998, "o", "at"]
[9.229999999999999, "o", " "]
[9.29, "o", "the"]
[9.35, "o", " "]
[9.41, "o", "most"]
[9.47, "o", " "]
[9.530000000000001, "o", "fundamental,"]
[9.590000000000002, "o", " "]
[9.650000000000002, "o", "atomic"]
[9.710000000000003, "o", " "]
[9.770000000000003, "o", "levels."]
[9.830000000000004, "o", " "]
[9.890000000000004, "o", "It"]
[9.950000000000005, "o", " "]
[10.010000000000005, "o", "describes"]
[10.070000000000006, "o", " "]
[10.130000000000006, "o", "phenomena"]
[10.190000000000007, "o", " "]
[10.250000000000007, "o", "like"]
[10.310000000000008, "o", " "]
[10.370000000000008, "o", "superposition,"]
[10.430000000000009, "o", " "]
[10.490000000000009, "o", "entanglement,"]
[10.55000000000001, "o", " "]
[10.61000000000001, "o", "and"]
[10.67000000000001, "o", " "]
[10.730000000000011, "o", "wave-particle"]
[10.790000000000012, "o", " "]
[10.850000000000012, "o", "duality"]
[10.910000000000013, "o", " "]
[10.970000000000013, "o", "that"]
[11.030000000000014, "o", " "]
[11.090000000000014, "o", "govern"]
[11.150000000000015, "o", " "]
[11.210000000000015, "o", "subatomic"]
[11.270000000000016, "o", " "]
[11.330000000000016, "o", "particles."]
[11.390000000000017, "o", "\r\n\r\n"]
[11.590000000000016, "o", "\ud83d\udcca Metrics:\r\n"]
[11.640000000000017, "o", "   TTFT: 45.2 ms\r\n"]
[11.690000000000017, "o", "   Throughput: 80.0 tokens/s\r\n"]
[12.240000000000018, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - Stopping LLMEngine\r\n"]
[12.290000000000019, "o", "2026-01-30 21:16:25,200 - sagellm_core.llm_engine - INFO - LLMEngine stopped\r\n"]
[12.34000000000002, "o", "\r\n"]
